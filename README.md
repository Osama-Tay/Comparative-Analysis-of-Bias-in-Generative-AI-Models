# Comparative Analysis of Bias in Generative AI Models

## Project Overview
This project presents a comprehensive investigation into biases inherent in leading generative AI models, specifically OpenAI's ChatGPT, Google's Gemini, and Meta's Llama. The primary objective is to systematically identify and analyze biases across multiple dimensions, including gender, race, socioeconomic status, and political perspectives. The findings aim to inform stakeholders about these biases and provide actionable recommendations for mitigating their impact in AI development.

## Table of Contents
- [Project Overview](#project-overview)
- [Research Methodology](#research-methodology)
- [Key Findings](#key-findings)
  - [ChatGPT](#chatgpt)
  - [Gemini](#gemini)
  - [Llama](#llama)
- [Recommendations](#recommendations)
- [Contributors](#contributors)
- [License](#license)
- [Contact Information](#contact-information)

## Research Methodology
This study employs a mixed-methods approach, integrating both quantitative and qualitative analyses to ensure a comprehensive evaluation of biases in generative AI models. The methodology consists of the following steps:

1. **Defining Research Questions and Selecting Models:** Identifying key bias-related questions and selecting AI models for assessment.
2. **Data Collection:** Conducting controlled interactions with each AI model using standardized prompts to ensure consistency and accuracy.
3. **Response Analysis and Scoring:** Developing a structured scoring system to assess bias presence based on observed stereotypes.
4. **Statistical Evaluation:** Analyzing collected data to identify and quantify patterns of bias.
5. **Comparison with Existing Literature:** Contextualizing findings within the broader field of AI ethics and bias research.
6. **Recommendation Development:** Proposing evidence-based strategies to mitigate identified biases in generative AI systems.

## Key Findings
### ChatGPT
- **Gender Bias:** Reinforces traditional gender stereotypes, frequently depicting women in caregiving roles and men in leadership positions.
- **Race Bias:** Displays limited racial diversity, often defaulting to white individuals in various professional roles.
- **Socioeconomic Bias:** Primarily portrays high-status professions as being held by white individuals, failing to reflect global diversity.
- **Political Bias:** Tends to align with dominant narratives, particularly in sensitive political discussions, often omitting alternative perspectives.

### Gemini
- **Gender Bias:** Overrepresents men in leadership and technical roles while depicting women predominantly in caregiving professions.
- **Race Bias:** Displays racial bias by defaulting to white individuals in various roles, leading to underrepresentation of ethnic diversity.
- **Socioeconomic Bias:** Tends to emphasize urban success stories, often neglecting representations of lower-income or marginalized communities.
- **Political Bias:** Aligns with mainstream Western perspectives, limiting exposure to diverse global viewpoints on sensitive issues.

### Llama
- **Gender Bias:** Exhibits minimal gender bias, with only one recorded instance of stereotype reinforcement across 35 evaluated scenarios.
- **Race Bias:** Underrepresents white-American individuals while prioritizing ethnic diversity, resulting in an inverse bias.
- **Socioeconomic Bias:** Demonstrates minimal bias, with a single instance linking housekeepers to lower-middle-class backgrounds.
- **Political Bias:** Limited overall bias but exhibits a slight tendency toward dominant narratives in sensitive political topics.

## Recommendations
To mitigate identified biases and improve fairness in AI-generated content, we propose the following strategies:

- **Data Oversight:** Conduct regular audits of training datasets to detect and rectify imbalances or bias indicators.
- **Diverse Representation:** Ensure that datasets incorporate balanced representation across gender, racial, and socioeconomic demographics.
- **Bias Evaluation Techniques:** Implement advanced bias detection methodologies during the model development phase.
- **Iterative Model Updates:** Continuously refine AI models based on empirical findings to address emerging biases.
- **Transparency and Accountability:** Maintain clear documentation on training data sources and model decision-making processes to foster trust and ethical AI deployment.

## Contributors
- Osama Aboalwafa
- Mohamed Abutouq
- Ibrahim Abdullah
- Mohamed Yakoub
- Mohamed Elmarzugi
- Zaid Awad

## License
This project is licensed under the MIT License. See the LICENSE file for details.

## Contact Information
For inquiries or further information, please contact the contributors via their respective email addresses.

